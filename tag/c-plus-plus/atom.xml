<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

    <title><![CDATA[Tag: C++ | Sample & Hold]]></title>
    <link href="http://Sample-Hold.github.io/tag/c-plus-plus/atom.xml" rel="self"/>
    <link href="http://Sample-Hold.github.io/"/>
    <updated>2013-10-17T18:47:18+02:00</updated>
    <id>http://Sample-Hold.github.io/</id>
    <author>
        <name><![CDATA[Frederic Ghilini]]></name>
        
    </author>
    <generator uri="http://octopress.org/">Octopress</generator>

    
    <entry>
        <title type="html"><![CDATA[Create a FFT Analyzer part III: building UI with Cocoa and Objective-C]]></title>
        <link href="http://Sample-Hold.github.io/2011/11/23/create-a-fft-analyzer-part-iii-building-ui-with-cocoa-and-objective-c/"/>
        <updated>2011-11-23T16:32:10+01:00</updated>
        <id>http://Sample-Hold.github.io/2011/11/23/create-a-fft-analyzer-part-iii-building-ui-with-cocoa-and-objective-c</id>
        <content type="html"><![CDATA[<p><a href="http://guileboard.files.wordpress.com/2011/11/images1.jpeg"><img src="http://guileboard.files.wordpress.com/2011/11/images1.jpeg?w=150" alt="" /></a>In this part of the tutorial, we are going to design a Cocoa UI in order to draw the spectrum graph computed by our unit, in which we&rsquo;ll create widgets so as to configure the FFT analysis.</p>

<p>Why using Cocoa? Well, for two reasons: I didn&rsquo;t want to introduce a too complex API in this tutorial (such as OpenGL), and I would like to show you how to mix C++ and Objective-C in the same XCode project. Don&rsquo;t worry, it doesn&rsquo;t bother if you&rsquo;re not experienced with Objective-C: we&rsquo;ll make a straightforward use of it and we&rsquo;ll clearly explain all the interactions between our GUI classes and our C++ code.</p>

<!-- more -->


<h3>One build target more</h3>

<p>First off, we ought to organize a bit our XCode project before we start coding our Cocoa UI. I may suggest you to create a new folder into &ldquo;Sources&rdquo; that will contain all your Objective-C code. Let&rsquo;s call it &ldquo;SpectrumCocoaView&rdquo;.</p>

<p>We need to add a new build target to our project:</p>

<ol>
<li><p> Choose the template &ldquo;Mac OS X > Framework &amp; Library > Bundle&rdquo; and call you target &ldquo;SpectrumCocoaView&rdquo;. Please note that we don&rsquo;t use the &ldquo;Automatic Reference Counting&rdquo; feature in this tutorial, so you may uncheck it. And yes, this time, you must link your target to the Cocoa framework.</p></li>
<li><p> Edit your new target&rsquo;s build settings and add this to the &ldquo;Other Linker flags&rdquo;: <em>-framework Foundation -framework AppKit </em></p></li>
<li><p> There&rsquo;s not much to say about build phases: we classically include the required headers, then our Objective-C sources, however we just must not forget to add a XIB file which describes our GUI. I&rsquo;ll explain this very soon.</p></li>
</ol>


<p>You have to make a &ldquo;build relationship&rdquo; between you two targets :</p>

<ol>
<li><p> Open the build phases for your C++ target called &ldquo;SimpleSpectrumAnalyzer&rdquo;.</p></li>
<li><p> Add a build phase of type &ldquo;Target dependencies&rdquo; <strong>positioned as your first operation</strong>.</p></li>
<li><p> Then add the product &ldquo;SpectrumCocoaView&rdquo; as a dependency.</p></li>
</ol>


<p>Perhaps you don&rsquo;t want to put your hands into problems for now, so you may prefer <a href="http://github.com/fredguile/SimpleSpectrumAnalyzer">grabbing our existing XCode project</a> before you continue your reading.</p>

<h3>Design your interface</h3>

<p>That&rsquo;s where you create a new XIB file (preferably in your &ldquo;Resources&rdquo; folder) in order to design your GUI. At this step, we just draw our GUI components, and keep all the logic inside Objective-C classes we&rsquo;ll create afterwards. It&rsquo;s a good occasion to separate concerns between components: our Spectrum Analyzer GUI will divide the work between two main classes.</p>

<p>Here are the components we need to add to this document:</p>

<ul>
<li><p>The root view, called &ldquo;SpectrumAnalyzerView&rdquo;: a <strong>Custom View</strong> responsible for all exchanges between the Audio Unit and the GUI, like sending/receiving parameters, or receiving new audio data to draw.</p></li>
<li><p>The subview, called &ldquo;SimpleSpectrumGraphView&rdquo;: a <strong>Custom View</strong> responsible for drawing the GUI using basic Cocoa objects such as Bezier curve, text labels, etc.</p></li>
<li><p>We add a child element to the subview: a <strong>TextField</strong> widget, that we&rsquo;ll use to give more precise informations about frequencies and magnitudes.</p></li>
</ul>


<p>Finally, We create a <strong>NSMenu </strong>widget in order to let users modify the Audio Unit parameters. It will pops up when you right-click anywhere in the SpectrumAnalyzerView.</p>

<p><a href="http://guileboard.files.wordpress.com/2011/11/capture-d_c3a9cran-2011-11-29-c3a0-18-14-07.png"><img src="http://guileboard.files.wordpress.com/2011/11/capture-d_c3a9cran-2011-11-29-c3a0-18-14-07.png?w=300" alt="" /></a></p>

<h3>Create GUI classes</h3>

<p>For each custom view that we have added above, we need to create a class owning the programming logic. Objective-C is quite similar than C++: you first define your classes into header files, then implement them in source files. There are two things you should know before creating them:</p>

<ul>
<li><p>Objective-C can contain either C or C++ code. It depends of the file&rsquo;s extension you choose when you create your implementation : .m stands for C, .mm for C++. To keep this tutorial simple, and because we&rsquo;ll include C++ headers in our Objective-C classes, I strongly suggest<strong> renaming all your .m extensions to .mm extensions</strong>.</p></li>
<li><p>There is no namespace in Objective-C, so Apple recommends to name all you classes using very specific names.</p></li>
</ul>


<p>Before you go, don&rsquo;t forget to choose the &ldquo;SpectrumCocoaView&rdquo; target each time you create a new Objective-C class. So we create these ones:</p>

<ul>
<li><p><strong>SimpleSpectrum_GraphView</strong></p></li>
<li><p><strong>SimpleSpectrum_UIView</strong></p></li>
<li><p>and a very important one, <strong>SimpleSpectrum_ViewFactory</strong></p></li>
</ul>


<p>What is it for? This latter class is responsible for binding your GUI with you Audio Unit, hence it must implement the <strong>AUCocoaUIBase</strong> protocol. What is a protocol? It&rsquo;s more or less like an interface in Java: by adding it to your class, you agree to implement all the methods defined inside. So in our case, it&rsquo;s necessary to implement this method:</p>

<pre><code>-(NSView *)uiViewForAudioUnit:(AudioUnit)inAudioUnit withSize:(NSSize)inPreferredSize {
if(![NSBundle loadNibNamed:@"SpectrumView" owner:self]) {
NSLog(@"Unable to load nib from view");
return nil;
}

[uiFreshlyLoadedView setAU:inAudioUnit];
NSView *returnView = uiFreshlyLoadedView;
uiFreshlyLoadedView = nil; // zero out pointer.  This is a view factory.  Once a view's been created

// and handed off, the factory keeps no record of it.
return [returnView autorelease];
}
</code></pre>

<h3>Bind UI widgets to IBActions</h3>

<p>This is the fun part of the Cocoa Framework. All you have to do is:</p>

<ol>
<li><p> in your Objective-C code:</p>

<ol>
<li><p>declare all your subviews and widgets as member variables of you custom class, using pointers to their base class</p></li>
<li><p>put the magic qualifier <strong>IBOutlet</strong> on each variable</p></li>
<li><p>create &ldquo;action methods&rdquo; that return the <strong>IBAction</strong> type and take an unique parameter of type <strong>id</strong></p></li>
</ol>
</li>
<li><p> in the XIB document:</p>

<ol>
<li><p>select each view (or widget) for which you have developed a custom class</p></li>
<li><p>define this custom class in the &ldquo;Class&rdquo; attribute (on the right pane of Xcode)</p></li>
<li><p>bind <strong>Outlets </strong>together, that is to say, bind views with their subview and their widgets</p></li>
<li><p>bind <strong>Received Actions </strong>with the methods you&rsquo;ve previously created</p></li>
</ol>
</li>
</ol>


<p><a href="http://guileboard.files.wordpress.com/2011/11/capture-d_c3a9cran-2011-11-29-c3a0-20-54-13.png"><img src="http://guileboard.files.wordpress.com/2011/11/capture-d_c3a9cran-2011-11-29-c3a0-20-54-13.png?w=179" alt="" /></a></p>

<p>So far, we have designed a basic Cocoa UI and we have bound the most important widgets to actions developed in Objective-C classes. We have had an overall sight of how our Spectrum Analyzer basically interacts with the Cocoa UI.</p>

<p>We&rsquo;ll soon study how to draw a beautiful spectrum analyzer, but in the meantime, we need to talk about the data we need to manage on both sides in order to transmit the FFT analysis to the UI.</p>

<h3>Create Audio Unit&rsquo;s parameters and properties</h3>

<p>Your GUI will communicate with your Audio Unit using two types of data:</p>

<ul>
<li><p><strong>parameters</strong>: they hold user settings. They are called by the Audio Unit during audio processing and they are called by the GUI classes when the user modify them through UI widgets,</p></li>
<li><p><strong>properties</strong>: they hold any kind of data exchanged between the Audio Unit, the Host and the GUI. They can be defined in the CoreAudio SDK, as well in your code as &ldquo;custom properties&rdquo;.</p></li>
</ul>


<p>For our Spectrum analyzer, we define these three parameters:</p>

<ul>
<li><p><strong>kSpectrumParam_BlockSize</strong>: the FFT block size, from 1024 to 16384 samples. By raising this parameters, we raise the FFT precision, but in the other hand we get slower computing/drawing times,</p></li>
<li><p><strong><strong>kSpectrumParam_SelectC</strong>hannel</strong>: a simple parameter to restrict FFT analysis on left or right channel (if our audio unit is inserted into a stereo bus),</p></li>
<li><p><strong>kSpectrumParam_Window</strong>: the window function we choose to compute our samples before we do FFT analysis.</p></li>
</ul>


<p>And we need those two custom properties:</p>

<ul>
<li><p><strong>kAudioUnitProperty_SpectrumGraphInfo</strong>: a simple structure that hold the infos our GUI needs to know before it can draw a spectrum graph,</p></li>
<li><p><strong>kAudioUnitProperty_SpectrumGraphData</strong>: an array of floating-point numbers to pass the computed magnitudes to the GUI.</p></li>
</ul>


<p>Building those parameters and properties on the Audio Unit side would require to add another endless part to this tutorial. Fortunately, there are many articles available on the net and I suggest reading <a href="http://developer.apple.com/library/mac/#documentation/MusicAudio/Conceptual/AudioUnitProgrammingGuide/Tutorial-BuildingASimpleEffectUnitWithAGenericView/Tutorial-BuildingASimpleEffectUnitWithAGenericView.html">the official Apple tutorial</a> if you want to get more details in creating them in your C++ code .</p>

<p>Still, we must comment some lines of code from the C++ class &ldquo;SimpleSpectrum&rdquo;:</p>

<ul>
<li><p>Parameters must be declared as soon as your Audio Unit initializes:</p>

<p>SimpleSpectrum::SimpleSpectrum(AudioUnit component) : AUEffectBase(component), mCAMutex(&ldquo;mutex&rdquo;){
&hellip;
SetParameter(kSpectrumParam_BlockSize, kBlockSize_Default);
SetParameter(kSpectrumParam_SelectChannel, kSelectChannel_Default);
SetParameter(kSpectrumParam_Window, kWindow_Default);
&hellip;
}</p></li>
<li><p>It&rsquo;s best to declare all parameters and properties in a separate C++ header: <em>SimpleSpectrumSharedData.h</em> in our case. That way, we could use C++ for our Audio Unit and restrict our GUI code to pure Objective-C and C</p></li>
<li><p>Basically, to use a parameter defined both in the Audio Unit and the GUI, we have to call:</p>

<ul>
<li><p>from the Audio Unit side: <em>GetParameter(kSpectrumParam_BlockSize)</em></p></li>
<li><p>from the Cocoa UI side: <em>AudioUnitGetParameter(mAU, kSpectrumParam_BlockSize, kAudioUnitScope_Global, 0, &amp;inValue)</em></p></li>
</ul>
</li>
<li><p> In this tutorial, we assume that the GUI has previously allocated sufficient memory <strong>before</strong> it requests any property content. Hence it&rsquo;s also responsible for freeing this memory when it&rsquo;s released. That&rsquo;s why the code that transmit our custom properties looks like this, without allocating anything:</p>

<p>&hellip;
case kAudioUnitProperty_SpectrumGraphData: {
   Float32<em> mData = (Float32</em>) outData;
   if(mInfos.mNumBins > 0) {
      mCAMutex.Lock();
      memcpy(mData, mComputedMagnitudes(), mInfos.mNumBins * sizeof(Float32));
      mCAMutex.Unlock();
   }
}</p></li>
<li><p>On the other side, in the class SimpleSpectrum_UIView class:</p>

<p>&hellip;
SpectrumGraphInfo graphInfo;
graphInfo.mNumBins = 0;
UInt32 sizeOfResult = sizeof(graphInfo);
ComponentResult result = AudioUnitGetProperty(mAU,
                                                  kAudioUnitProperty_SpectrumGraphInfo,
                                                  kAudioUnitScope_Global,
                                                  0,
                                                  &amp;graphInfo,
                                                  &amp;sizeOfResult);</p>

<p>if(result == noErr &amp;&amp; graphInfo.mNumBins > 0) {
        CAAutoFree graphData;
        graphData.allocBytes(sizeOfResult = graphInfo.mNumBins * sizeof(Float32));</p>

<pre><code>    result = AudioUnitGetProperty(mAU,
                                  kAudioUnitProperty_SpectrumGraphData,
                                  kAudioUnitScope_Global,
                                  0,
                                  graphData(),
                                  &amp;sizeOfResult);

    [graphView plotData: graphData givenInfos: graphInfo];
</code></pre>

<p>}</p></li>
<li><p>The most of you, readers, will have noticed that we protect access to the computed magnitudes array with a mutex, provided by the class <strong>CAMutex</strong> (found in the &ldquo;PublicUtility&rdquo; folder). This is because the GUI code and the Audio Unit code both run in separate threads. The former may ask for the magnitudes <strong>while </strong>they are being computed, so we must synchronize this.</p></li>
<li><p><strong>Edit 15/01/12</strong>: I committed a few changes on the lines above that brought some performance tweaks. It looks like the mutex isn&rsquo;t that necessary, and I also removed some dynamic memory allocations to save some CPU cycles.</p></li>
</ul>


<h3>Synchronize Audio Unit&rsquo;s data with UI</h3>

<p>So&hellip; how can we draw the spectrum graph once magnitudes have been computed by our <em>SimpleSpectrumProcessor</em> class? We have two options:</p>

<ul>
<li><p>We could add a <strong>NSTimer </strong>in the class <strong>SimpleSpectrum_UIView </strong>that cyclically &ldquo;asks&rdquo; for the computed magnitudes.</p></li>
<li><p>We could &ldquo;notify&rdquo; the class <strong>SimpleSpectrum_UIView </strong>each time new magnitudes have been computed.</p></li>
</ul>


<p>I tried both solutions, and I prefer the second one. To achieve this, you need to create a callback listener in the class <strong>SimpleSpectrum_UIView</strong>, and follow these guidelines:</p>

<ul>
<li><p>create the method <strong>dispatchAudioUnitEventProc </strong>with a special signature and register it as a callback method (SimpleSpectrum_UIView.mm, line 188)</p></li>
<li><p>register an <strong>AudioUnitEvent</strong> for every parameter/property you&rsquo;ve created (SimpleSpectrum_UIView.mm, lines 194-215)</p></li>
<li><p>catch a &ldquo;property changed&rdquo;  event for our custom properties <strong>kAudioUnitProperty_SpectrumGraphData</strong> and <strong>kAudioUnitProperty_SpectrumGraphInfo</strong>(SimpleSpectrum_UIView.mm, lines 144-149)</p></li>
<li><p>send this &ldquo;property changed&rdquo; event in the audio unit main code (SimpleSpectrum.cpp, line 89)</p></li>
<li><p>write a method that will pass properties to the UI (SimpleSpectrum.cpp, lines 95-150)</p></li>
<li><p>write a method that will draw magnitudes, or at least delegate this draw to the class <strong>SimpleSpectrum_GraphView</strong> (SimpleSpectrum_UIView.mm, lines 224-251)</p></li>
</ul>


<p>Okay, I admit that there is a lot of steps. There are many lines of code involved in this synchronization, written with different semantics, three programming languages, etc. Things could be easier, that&rsquo;s we&rsquo;ll perhaps discover when we&rsquo;ll write our first VST in an upcoming tutorial ;)</p>

<p>Though, our spectrum is still not moving. We need to talk about the class <strong>SimpleSpectrum_GraphView</strong> and its drawing techniques.</p>

<h3>Bringing the spectrum alive</h3>

<p>There are three things I would like to write about in this class.</p>

<p>First of all, the object <strong>NSBezierPath </strong>is my easy method for drawing the spectrum. All I have to do is moving to a certain <strong>NSPoint,</strong> then draw lines/curves using the methods <em>lineToPoint</em> and <em>curveToPoint</em> (or may I write &ldquo;messages&rdquo;? Since we are writing Objective-C&hellip;). There is a good tutorial on this <a href="http://developer.apple.com/library/mac/#documentation/Cocoa/Conceptual/CocoaDrawingGuide/Introduction/Introduction.html">in the Apple documentation</a>.</p>

<p><a href="http://guileboard.files.wordpress.com/2011/11/bezier_curvec1.png"><img src="http://guileboard.files.wordpress.com/2011/11/bezier_curvec1.png" alt="" /></a></p>

<p>Secondly, I use the object <strong>NSAffineTransform</strong> each time I need to change my coordinate system. This is important to understand that we have to draw several different things:</p>

<ul>
<li><p>the grid, from left-to-right and top-to-bottom</p></li>
<li><p>the frequencies/decibels labels, by transforming twice the coordinate system</p></li>
<li><p>the spectrum curve from left-to-right</p></li>
</ul>


<p>So either you get an headache with maths, either you feel sick using <strong>NSAffineTransform</strong>. I personally got an headache and felt sick, but the use of <strong>NSAffineTransform</strong> has structured my code. You should look at <a href="http://developer.apple.com/library/mac/#documentation/Cocoa/Conceptual/CocoaDrawingGuide/Transforms/Transforms.html#//apple_ref/doc/uid/TP40003290-CH204-BCIFCIHJ">this tutorial</a> for further explanations.</p>

<p>At last, you might notice a few additional things:</p>

<ul>
<li><p>that we have used a bunch of methods so as to draw frequencies/decibels in a logarithmic scale (SimpleSpectrum_GraphView.mm, lines 87-145)</p></li>
<li><p>that we have added some mouse callbacks in order to display the precise frequency/decibel under the mouse cursor (SimpleSpectrum_GraphView.mm, lines 334-374)</p></li>
</ul>


<p>We now have everything we need to build a clean Cocoa UI, and at this time, I hope that you have everything set up in your XCode environment and that you can hit &ldquo;Build&rdquo; to get your first debug release.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Create a FFT Analyzer part II: designing our spectral processor]]></title>
        <link href="http://Sample-Hold.github.io/2011/11/23/create-a-fft-analyzer-part-ii-designing-our-spectral-processor/"/>
        <updated>2011-11-23T16:26:47+01:00</updated>
        <id>http://Sample-Hold.github.io/2011/11/23/create-a-fft-analyzer-part-ii-designing-our-spectral-processor</id>
        <content type="html"><![CDATA[<p><a href="http://guileboard.files.wordpress.com/2011/11/images.jpeg"><img src="http://guileboard.files.wordpress.com/2011/11/images.jpeg" alt="" /></a>We briefly introduced the FFT part of the Accelerated Framework in Part I of this tutorial.</p>

<p>We are now going to focus on the vDSP library and create the C++ class responsible for doing the spectral analysis work of our input samples. We want to keep it simple, with a few public methods, however we would like to perform FFT analysis on different frame sizes. So, one of our challenges is to design a circular buffer as member variable, which is a common pattern in audio programming.</p>

<!-- more -->


<h3>Xcode Setup</h3>

<p>In case you don&rsquo;t have your development environment initialized with a clean template for building audio units, I suggest you <a href="http://github.com/fredguile/SimpleSpectrumAnalyzer">download the source code of this tutorial</a>, then open the C++ class called <em>SimpleSpectrumProcessor.h</em> located in the &ldquo;Sources/SpectrumAU&rdquo; folder.</p>

<p>First of all, if you look at the &ldquo;PublicUtility&rdquo; folder of the CoreAudio SDK, you may notice a quite similar class called &ldquo;CASpectralProcessor&rdquo;. Actually, you can consider our class as a reduced version of &ldquo;CASpectralProcessor&rdquo;, more readable to my opinion, with a different buffers organization that allows the use of various FFT sizes upon time (between 1024 and 16384 frames). As common design, we will reuse the classes <em>CAAutoFree</em> and <em>CAAutoArrayDelete</em> so as to implement each data buffer. The former is basically an alternative to the std::auto smart pointer with the same restrictions on pointer ownership, but since it&rsquo;s using <em>malloc</em> to allocate memory, it will guarantee that the allocated memory is aligned on a 16-bits boundary (what vecLib needs). The latter is a similar version using &ldquo;new&rdquo; for memory allocation.</p>

<p>So you need to include the header &ldquo;PublicUtility/CAAutoDisposer.h&rdquo;, either in our class header, either in the project&rsquo;s precompiled headers section. You also need &lt;Accelerate/Accelerate.h> for the vDSP library and the &ldquo;vecLib.framework&rdquo; binary added to your build settings.</p>

<h3>SimpleSpectrumProcessor.h</h3>

<pre><code>class SimpleSpectrumProcessor {
public:
enum Window { Rectangular = 1, Hann = 2, Hamming = 3, Blackman = 4 };
private:
UInt32 mNumChannels;
UInt32 mRingBufferCapacity;
UInt32 mRingBufferPosRead;
UInt32 mRingBufferPosWrite;
UInt32 mRingBufferCount;
UInt32 mFFTSize;
FFTSetup mFFTSetup;
bool mFFTSetupCreated;
struct ChannelBuffers {
CAAutoFree&lt;Float32&gt; mRingBufferData;
CAAutoFree&lt;Float32&gt; mInputData;
CAAutoFree&lt;Float32&gt; mSplitData;
CAAutoFree&lt;Float32&gt; mOutputData;
CAAutoFree&lt;DSPSplitComplex&gt; mDSPSplitComplex;
};

CAAutoArrayDelete&lt;ChannelBuffers&gt; mChannels;
CAAutoFree&lt;Float32&gt; mWindowData;

protected:
void InitFFT(UInt32 FFTSize, UInt32 log2FFTSize, UInt32 bins);
void ExtractRingBufferToFFTInput(UInt32 inNumFrames);
void ApplyWindow(Window w);

public:
SimpleSpectrumProcessor();
virtual ~SimpleSpectrumProcessor();
void Allocate(UInt32 inNumChannels, UInt32 ringBufferCapacity);
bool CopyInputToRingBuffer(UInt32 inNumFrames, AudioBufferList* inInput);
bool TryFFT(UInt32 inFFTSize, Window w = Rectangular);
CAAutoFree&lt;Float32&gt; GetMagnitudes(Window w, UInt32 channelSelect = 3);
};
</code></pre>

<p>The first member variables are storing our circular buffer&rsquo;s capacity, fill count and two locations for reading/writing. Next, FFTSetup is holding the FFT weights array required by vDSP to perform the FFT transform. Concerning the buffers:</p>

<ul>
<li><p><em>mChannels</em> is an array containing various auto-pointers for each buffer we need : input/output data, split buffer to hold complex numbers that we&rsquo;ll access using our specific pointer <em>mDSPSplitComplex </em>(we&rsquo;ll explain that in a few seconds),</p></li>
<li><p><em>mWindowData </em>holds floating-pont numbers of the window function we&rsquo;ll choose to limit frequency leakage on our frequency spectrum (see <a href="http://sample-hold.com/2011/11/23/create-a-fft-analyzer-part-i-prerequisites-concerns-and-setup/">part I</a>),</p></li>
<li><p><em>mFFTSize </em>holds the FFT size, and we propose 5 values : 1024, 2048, 4096, 8192 or 16384 samples.</p></li>
</ul>


<p>By using auto-pointers as member variables (instead of simple pointers),  we use the RAII (&ldquo;resource acquisition is initialization&rdquo;) technique of C++ to free our buffers when our Audio Unit is released (or, of course, if an exception occur). That is to say, destructors for <em>CAAutoFree </em>and <em>CAAutoArrayDelete</em> will be called automatically when our main class is released.</p>

<p>Here is the basic workflow of this class:</p>

<ul>
<li><p>We first call <em>Allocate()</em> to initialize the circular buffer with a capacity of 16384 samples,</p></li>
<li><p> Each time our plugin render, we copy N frames to our circular buffer using <em>CopyInputToRingBuffer()</em>, then we call <em>TryFFT()</em> to compute those data,</p></li>
<li><p>In case the method <em>TryFFT()</em> returns successfully, we call <em>GetMagnitudes() </em>to obtain a floating-point array of magnitudes to display on a graph. We can get magnitudes for left/right channel separately (<em>channelSelect </em>is 1 or 2), or we can look at the average magnitudes of a stereo channel (<em>channelSelect </em>is 3).</p></li>
</ul>


<h3>Using a Ring Buffer</h3>

<p><a href="http://guileboard.files.wordpress.com/2011/11/200px-circular_buffer-svg.png"><img src="http://guileboard.files.wordpress.com/2011/11/200px-circular_buffer-svg.png?w=150" alt="" /></a>Audio Units generally capture N input samples each time they are rendered, N being set by the host in which they operate. N has a value usually lower than the minimum number of  frames required for computing FFT, so before we can provide at least 1024 samples to FFT, we have those N samples stored into a ring buffer over a few cycles.</p>

<p> This kind of buffer is circular: thus, it never overflows. We always keep K samples in the ring buffer, K being the buffer&rsquo;s capacity. That&rsquo;s why we maintain two<em> int pointers</em> :</p>

<ul>
<li><p><em>mRingBufferPosRead</em> indicates where we must read when we extract samples to compute FFT,</p></li>
<li><p><em>mRingBufferPosWrite </em> is the same for writing into the ring buffer.</p></li>
</ul>


<p>We use an &ldquo;overlap-add&rdquo; algorithm to fill our ring buffer, that is, we possibly split the N samples being added, on part being stored at the end of the buffer and the other being stored from the beginning index. You can look at the method <em>CopyInputToRingBuffer</em> to get an example of such algorithm.</p>

<p>We also use this technique to extract N samples from the ring buffer (look at the protected method <em>ExtractRingBufferToFFTInput() </em> method). However, we ensure that enough samples have been stored into the buffer before we call this method.</p>

<p>You may note that our implement isn&rsquo;t thread-safe, hence all calls to the <em>SimpleSpectrunProcessor</em>&rsquo;s methods must be called from the same thread.</p>

<h3>Data packing for vDSP FFT</h3>

<p>The library vDSP.h provides two structures for packing the N samples you pass to the FFT: <em>DSPComplex </em>and <em>DSPSplitComplex</em>. You should first read the <a href="http://developer.apple.com/library/ios/#documentation/Performance/Conceptual/vDSP_Programming_Guide/UsingFourierTransforms/UsingFourierTransforms.html">neat article made by Apple on data packing</a>. Here is a summary:</p>

<ol>
<li><p> Your N samples are first stored into a 16-bits aligned float-point array, called our <em>input buffer</em>,</p></li>
<li><p> Whereas a real FFT would produce 2N complex numbers, the vDSP FFT truncates the result to store N/2 complex numbers in our <em>output buffer:</em> hence the input/output buffers have the same N size,</p></li>
<li><p> Prior to the FFT function, you need to reorganize your <em>input buffer</em> by copying your N samples into a <em>split buffer</em>.</p></li>
</ol>


<p>This <em>split buffer</em> is first initialized as a 16-bits aligned floating-point array, as you may read in the protected method <em>InitFFT()</em>. It is next accessed using a <em>DSPSplitComplex </em>structure that &ldquo;groups&rdquo; floating-point together, for this buffer to behave as an array of N/2 complex numbers (with both real and imaginary parts).</p>

<p><em><em>This is important to remember that the last mandatory step before we can compute FFT is to reorganize you </em>split buffer</em> by calling <strong>vDSP_ctoz</strong>: this will &ldquo;pack&rdquo; floating-point numbers for the vDSP FFT by a stride of 2.</p>

<p>For instance,  if your input buffer is [x1, x2, x3, x4, x5, x6, x7, x8], then your split buffer will be [x1, x5, x2, x6, x3, x7, x4, x8]. After FFT, you&rsquo;ll get [c1.real, c1.imag, c2.real, c2.imag, c3.real, c3.imag, c4.real, c4.imag]. But, if the <em>DSPSplitComplex</em> structure can see interleaved complex numbers like previously, our split buffer remains an aligned buffer with [c1.real, c2.real, c3.real, c1.imag, c2.imag, c3.imag, c4.imag].</p>

<h3>The power of SIMD</h3>

<p><a href="http://guileboard.files.wordpress.com/2011/11/images-1.jpeg"><img src="http://guileboard.files.wordpress.com/2011/11/images-1.jpeg?w=150" alt="" /></a>What is the plot of having all those buffers ? We could have reworked things to diminish memory footprint.</p>

<p>Instead, we&rsquo;ll use the great SIMD features of the vDSP library with no proprietary code at all!  The benefit here is to drastically reduce the computing time of a large number of samples. Furthermore, vDSP provide numerous mathematical functions that will help us achieve our sound analysis.</p>

<p>At first sight, there are a lot of functions. You&rsquo;ll soon get use to the naming conventions used by Apple to find the good one: for instance, if you are looking to a vector-scalar operation, you may search for a function named vDSP_vs[something] or vDSP_sv[something]. It you are working with 64-bits IEEE floating point numbers, you will look at the functions named vDSP_[something]D (D for double).</p>

<p>Here is what our SimpleSpectrumAnalyzer will do:</p>

<ol>
<li><p> First, we determine our current windowing function by simply calling one of the ready-to-use functions: <strong>vDSP_hann_window </strong>(Hann), <strong>vDSP_hamm_window</strong> (Hamming) or <strong>vDSP_blkman_window</strong> (Blackman)</p></li>
<li><p> We multiply our N samples with the window function using <strong>vDSP_vmul</strong></p></li>
<li><p> As seen above, our DSPComplexSplit structure is organized by <strong>vDSP_ctoz</strong></p></li>
<li><p> We compute FFT with <strong>vDSP_fft_zip </strong>(as a naming convention, &ldquo;z&rdquo; stands for complex numbers),</p></li>
<li><p> Magnitude of a complex number can be obtained with <strong>vDSP_zvabs </strong>(we could have possibly used <strong>vDSP_zvmags</strong>, see below)</p></li>
<li><p> We next normalize our magnitudes, by dividing then by two, using <strong>vDSP_vsdiv </strong>(since we got N/2 complex numbers which is half of the N input samples)</p></li>
<li><p> We convert magnitudes to a decibel value using <strong>vDSP_vdbconv</strong></p></li>
<li><p> We correct each decibel values by applying a Db correction with <strong>vDSP_vadd</strong></p></li>
<li><p> We could possible obtain an average value for left and right channels using <strong>vDSP_vadd</strong> and <strong>vDSP_vsdiv</strong>.</p></li>
</ol>


<p>We&rsquo;ll leave these steps unchanged to keep this tutorial simple, though we could have tweaked things a bit. As you know, the decibel formula is given by:</p>

<p><a href="http://guileboard.files.wordpress.com/2011/11/062fdd96385ff2ddfdb4426194c49b29.png"><img src="http://guileboard.files.wordpress.com/2011/11/062fdd96385ff2ddfdb4426194c49b29.png" alt="" /></a></p>

<p>As an optimization, rather than multiplying/dividing U1 or U2, we could have left U1 unchanged, called <strong>vDSP_vdbconv</strong>, then take this into account when applying our dB correction. Indeed, every multiplication or division on U1 can translate into an addition or deletion on log10(U1). In the same manner, we could have used <strong>vDSP_zvmags</strong> instead of <strong>vDSP_zvabs</strong> and saved one <em>sqrt </em>operation.</p>

<h3>Using SimpleSpectrumProcessor in our Audio Unit</h3>

<p>We&rsquo;ll wrap up this part by showing you how our SimpleSpectrumProcessor is used in the main code. Basically:</p>

<ul>
<li><p>It&rsquo;s a member variable of the main class <em>SimpleSpectrum.h</em> (hence all of our resources are released using the RAII technique),</p></li>
<li><p>We override the <em>AUEffectBase::Render()</em> method, responsible for grabbing N samples from the audio inputs and computing FFT,</p></li>
<li><p>You may notice that we aren&rsquo;t using the class <em>SimpleSpectrumKernel</em> at all, even if we have overridden the method <em>AUKernelBase::Process()</em>, which is a required step for our Audio Unit to be validated by the <strong>auval</strong> tool.</p></li>
</ul>


<p>Here the snippet of the main work:</p>

<pre><code>...
AudioBufferList&amp; inputBufList = GetInput(0)-&gt;GetBufferList();
mProcessor.CopyInputToRingBuffer(inFramesToProcess, &amp;inputBufList);
...
if(mProcessor.TryFFT(currentBlockSize, currentWindow)) {
...
CAAutoFree&lt;Float32&gt; magnitudes = mProcessor.GetMagnitudes(currentWindow, channelSelect);
...
}
</code></pre>

<h3>Conclusion</h3>

<p>I let you examine the Apple documentation to get acquainted of the different methods you can override from the base classes <em>AUEffectBase </em>and <em>AUBase</em>. In an upcoming tutorial, we will make a better use of the <em>AUKernelBase</em> class, but in the meantime, we shall look how we&rsquo;ll build a GUI to draw our spectrum data.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Getting started with Audio Units on OS X Lion and XCode 4.2.1]]></title>
        <link href="http://Sample-Hold.github.io/2011/11/23/getting-started-with-audio-units-on-os-x-lion-and-xcode-4-2-1/"/>
        <updated>2011-11-23T15:59:23+01:00</updated>
        <id>http://Sample-Hold.github.io/2011/11/23/getting-started-with-audio-units-on-os-x-lion-and-xcode-4-2-1</id>
        <content type="html"><![CDATA[<p><a href="http://guileboard.files.wordpress.com/2011/11/home-ios-sdk.png"><img src="http://guileboard.files.wordpress.com/2011/11/home-ios-sdk.png" alt="" /></a>Apple usually takes care of their developers community.  Whereas they lately delivered an impressive update of their Xcode IDE with tons of new features (read a <a href="http://pilky.me/view/28">cool  review here</a>), they surprisingly removed the project template for creating Audio Units. Nevertheless, let&rsquo;s see how to create a new unit from scratch&hellip;</p>

<!-- more -->


<p>Of course, the Core Audio SDK is still located in /Developer/Extras/CoreAudio and it&rsquo;s still possible to develop Audio Units with XCode 4.2. So you have two solutions :</p>

<ul>
<li><p>either you grab a sample code from Apple documentation (like &ldquo;FilterDemo&rdquo; for instance) and migrate it to suit the latest changes done in OS X Lion for the Core Audio SDK (there is an <a href="http://developer.apple.com/library/mac/#technotes/tn2276/_index.html#//apple_ref/doc/uid/DTS40011031">official technical note to read here</a>),</p></li>
<li><p>or you can learn, by following this tutorial, how to build you audio unit template from scratch in only a few steps !</p></li>
</ul>


<p><strong>EDIT for XCode 4.3.2 users: You may have noticed that starting from version 4.3.2, XCode is now a bundled app installed in /Applications. There is no more /Developer folder and since you are likely to use the CoreAudio API, you absolutely need to dowload the optional package named &ldquo;Audio Tools for XCode&rdquo; from the Apple website. Please click on XCode > Open Developer Tool > More Developer Tools&hellip; to reach the dowload page. And of course, you&rsquo;ll have to rewrite by yourself some links provided in this tutorial.</strong></p>

<h3>Create the project</h3>

<p>You need to create a new project using the template &ldquo;Mac OS X > Framework &amp; Library >Bundle&rdquo;.</p>

<p>Indeed, an Audio Unit is basically a bundle with a different file name extension &ldquo;.component&rdquo;. When asked, select &ldquo;Cocoa&rdquo; as framework, even if none of the proposed choices suit our needs for now. We&rsquo;ll clean those unwanted libraries later.</p>

<h3>Organize your files</h3>

<p>Your project must contain at least :</p>

<ul>
<li><p>one group for storing all C++ sources files, including your created classes and some sources coming from the CoreAudio SDK you will necessarily use,</p></li>
<li><p>one group for storing your resources, including a &ldquo;property list&rdquo; manifest  that describes your audio unit,</p></li>
<li><p>possibly one additional folder for C++ &ndash; or Objective-C sources &ndash; to create a GUI for your unit. However, for sake of simplicity, we&rsquo;ll discuss this in another tutorial. Leave it for now.</p></li>
</ul>


<p>By the way, don&rsquo;t neglect the &ldquo;Identity&rdquo; pane displayed when you open the rightmost view. You&rsquo;ll find two fields, &ldquo;Location&rdquo; and &ldquo;Full Path&rdquo; that can help you cleaning the mess if you want to add / delete a lot of files, or create new groups that &ldquo;map&rdquo; to existing folders in your project directory.</p>

<h3><a href="http://guileboard.files.wordpress.com/2011/11/identity.png"><img src="http://guileboard.files.wordpress.com/2011/11/identity.png" alt="" /></a></h3>

<h3>Tune your deployment target</h3>

<p>Click on the project&rsquo;s name to display the available deployment targets.</p>

<p>You can reuse the default target created by Xcode. The first tab &ldquo;Info&rdquo; shows the content of the property list file located in your resources folder (if not, check the path entered in the tab &ldquo;build settings&rdquo;, under the key &ldquo;Info.plist File&rdquo;). There is only one piece of information missing here : you must add a new Dictionary called &ldquo;AudioComponent&rdquo; containing at least  7 strings :</p>

<ul>
<li><p><strong>manufacturer</strong>: your name</p></li>
<li><p><strong>factoryFunction</strong>: the classname of your factory, for this tutorial type &ldquo;MyTestedPluginFactory&rdquo;</p></li>
<li><p><strong>subtype</strong>: a 4-alphanumeric code categorizing your unit, for instance &ldquo;TEST&rdquo;</p></li>
<li><p><strong>description</strong>: a brief description</p></li>
<li><p><strong>type</strong>: a 4-alphanumeric code defining your unit type. Please consult SDK documentation to get all the available types : for this tutorial, we are creating an audio effect, so type &ldquo;aufx&rdquo;</p></li>
<li><p><strong>name</strong>: your plugin&rsquo;s name</p></li>
<li><p><strong>version</strong>: an hexadecimal number defining the version number of the unit. The magic here wants you to enter OxMMMMmmHH, where MMMM is major version, mm is minor version and HH is hotfix number. But if, like me, you want to test your updated plugin every time you compile a new version, just enter &ldquo;0xFFFFFFFF&rdquo;.</p></li>
</ul>


<p><a href="http://guileboard.files.wordpress.com/2011/11/info.png"><img src="http://guileboard.files.wordpress.com/2011/11/info.png" alt="" /></a></p>

<p>Next, move ahead to the tab &ldquo;Build settings&rdquo;. Toggle the filter from &ldquo;Basic&rdquo; to &ldquo;All&rdquo; and proceed to a few changes on values :</p>

<ul>
<li><p>Architectures: I suggest creating a standard 32/64-bit Intel binary</p></li>
<li><p>Build active architecture only: choose &ldquo;no&rdquo;</p></li>
<li><p>Compiler for C/C++/Objective-C: this is not mandatory, but if you wish to use the new compiler LLVM 3.0, help yourself</p></li>
<li><p>Linking > Other linker flags: ensure &ldquo;-bundle&rdquo; is specified</p></li>
<li><p>Wrapper extension: change this extension and write &ldquo;component&rdquo;</p></li>
<li><p>Rez Search path: You need two values here</p>

<ul>
<li><p>/Developer/Extras/CoreAudio/AudioUnits/AUPublic/AUBase</p></li>
<li><p>/System/Library/Frameworks/CoreServices.framework/Frameworks/CarbonCore.framework/Versions/A/Headers</p></li>
</ul>
</li>
<li><p>Precompile prefix header: choose &ldquo;yes&rdquo;. I suggest using the one provided by the Xcode template.</p></li>
</ul>


<p>There will be one more key to adjust, but we can&rsquo;t see it until we have modified the &ldquo;Build phases&rdquo; first. So let&rsquo;s move to this third tab.</p>

<h3>Refactor the build phases</h3>

<p>Honestly, I find the XCode build system absolutely wonderful. Everything you need is to add a few build phases then XCode will compile and link your binary without asking too much questions.</p>

<p>Here are the build phases to add for our Audio Unit:</p>

<ol>
<li><p> Copy Bundle Resources: this may already exist. You will necessarily include in this phase the Info.PList we tweaked earlier.</p></li>
<li><p> Copy Headers: necessary to compile you C++ header files. We&rsquo;ll add files to this phase later.</p></li>
<li><p> Compile Sources: necessary to compile you C++ source code. Again, we&rsquo;ll add files to this phase later.</p></li>
<li><p> Link Binary with libraries: do your shopping but add at least three libraries : &ldquo;CoreServices.framework&rdquo;, &ldquo;AudioToolbox.framework&rdquo; and &ldquo;AudioUnit.framework&rdquo;. Remove everything else (even &ldquo;Cocoa&rdquo;).</p></li>
<li><p> Build Carbon Resources: it looks like you won&rsquo;t see this build phase until you create a file named &ldquo;MyTestedPlugin.r&rdquo; in your project (preferably in your &ldquo;Sources&rdquo;  group). Create it, then go back to your build phases, then you will be able to add this phase and include the file above.</p></li>
</ol>


<p>There are a few additional build phases we could discuss, but I reserve them for an upcoming tutorial.</p>

<p>Wait&hellip; you still need to go back to the &ldquo;Build settings&rdquo; tab and change the remaining key &ldquo;Other Rez Flag&rdquo;, by entering this:</p>

<pre><code>-d i386_$i386 -I /System/Library/Frameworks/CoreServices.framework/Frameworks/CarbonCore.framework/Versions/A/Headers -I /Developer/Extras/CoreAudio/AudioUnits/AUPublic/AUBase
</code></pre>

<p>Here we are.</p>

<h3>Fine-tune your precompiled header</h3>

<p>Here is the minimal precompiled header you would write for your Audio Unit :</p>

<pre><code>#if !defined(__COREAUDIO_USE_FLAT_INCLUDES__)
#include &lt;CoreAudio/CoreAudioTypes.h&gt;
#include &lt;CoreFoundation/CoreFoundation.h&gt;
#else
#include &lt;CoreAudioTypes.h&gt;
#include &lt;CoreFoundation.h&gt;
#endif

#include "AUEffectBase.h"
#include &lt;AudioToolbox/AudioUnitUtilities.h&gt;
</code></pre>

<h3>Add CoreAudio files to your project</h3>

<p>Right-click on your &ldquo;Sources&rdquo; group and choose &ldquo;Add files to MyTestedPlugin&hellip;&rdquo;.</p>

<p>Move to /Developer/Extras/CoreAudio.</p>

<p>I&rsquo;ll give you a precious advice here: before you click on &ldquo;Add&rdquo;, ensure that &ldquo;Add to Targets: MyTestedPlugin&rdquo; and &ldquo;Create groups for any added folders&rdquo; are <strong>selected</strong>.</p>

<p>You will find below the list of the folders/files you absolutely need to add to your project :</p>

<ul>
<li><p>AudioUnits/AUPublic/AUBase</p></li>
<li><p>AudioUnits/AUPublic/OtherBases/AUEffectBase.*</p></li>
<li><p>AudioUnits/AUPublic/Utility</p></li>
<li><p>PublicUtility/CAVectorUnit.*</p></li>
<li><p>PublicUtility/CAAudioChannelLayout.*</p></li>
<li><p>PublicUtility/CAHostTimeBase.*</p></li>
<li><p>PublicUtility/CAStreamBasicDescription.*</p></li>
<li><p>PublicUtility/CADebugMacros.*</p></li>
<li><p>PublicUtility/CAException.*</p></li>
<li><p>PublicUtility/CAXException.*</p></li>
<li><p>PublicUtility/CAAutoDisposer.h</p></li>
<li><p>PublicUtility/CAMath.h</p></li>
<li><p>PublicUtility/CAThreadSafeList.*</p></li>
</ul>


<p>Normally, all the .h and .cpp files have been added automatically to the &ldquo;Copy headers&rdquo; and &ldquo;Compile sources&rdquo; build phases. If not, you&rsquo;ll have to add them manually by editing your build phases.</p>

<h3>It&rsquo;s time to code !</h3>

<p>You may create at least one header file and one cpp file for your custom classes. For the purpose of our tutorial, here are the minimalistic classes you need to copy'n'paste:</p>

<pre><code>class MyTestedPluginKernel : public AUKernelBase {
public:
    MyTestedPluginKernel(AUEffectBase * inAudioUnit);
    virtual void Process(Float32 const* inSourceP,
                         Float32 * inDestP,
                         UInt32 inFramesToProcess,
                         UInt32 inNumChannels,
                         bool &amp; ioSilence);
};

class MyTestedPlugin : public AUEffectBase {
public:
    MyTestedPlugin(AudioUnit component);
    virtual OSStatus Version() { return 0xFFFFFF; }
    virtual OSStatus Initialize();
    virtual AUKernelBase * NewKernel() { return new MyTestedPluginKernel(this); }
};

AUDIOCOMPONENT_ENTRY(AUBaseFactory, MyTestedPlugin)

MyTestedPluginKernel::MyTestedPluginKernel(AUEffectBase * inAudioUnit ) : AUKernelBase(inAudioUnit) {}

void MyTestedPluginKernel::Process(Float32 const* inSourceP, Float32 * inDestP, UInt32 inFramesToProcess, UInt32 inNumChannels, bool &amp; ioSilence) {
//This code will pass-thru the audio data.
//This is usually where you want to process data to produce an effect.
}

MyTestedPlugin::MyTestedPlugin(AudioUnit component) : AUEffectBase(component) {}

OSStatus MyTestedPlugin::Initialize() {
OSStatus result = AUEffectBase::Initialize();
if(result == noErr ) {
   // do something
}
return result;
}
</code></pre>

<p>You ought to not omit the macro AUDIOCOMPONENT_ENTRY, since it&rsquo;s responsible for creating the stub classes MyTestedPluginEntry and MytestedPluginFactory as entry points for your Audio Unit.</p>

<h3>Populate Carbon resource file</h3>

<p>Remember the file &ldquo;MyTestedPlugin.r&rdquo; you created earlier ? It&rsquo;s time to fill it with standard content :</p>

<pre><code>#include &lt;AudioUnit/AudioUnit.r&gt;

#define RES_ID    1000
#define COMP_TYPE 'aufx'
#define COMP_SUBTYPE 'TEST'
#define COMP_MANUF 'FRED'
#define VERSION 0xFFFFFFFF
#define NAME "Test Plugin"
#define DESCRIPTION "description"
#define ENTRY_POINT "MyTestedPluginEntry"

#include "AUResources.r"
</code></pre>

<p>This step remains to keep backward compatibility with previous versions of CoreAudio SDK. You may  copy and past the information you wrote in the Info.PList.</p>

<p>I suggest to try compiling your project after you have finished this step. If you get any &ldquo;Rez error&rdquo;, you should check that in your build phase &ldquo;Build Carbon Resources&rdquo;, the file above is the <strong>only</strong> file added to the task.</p>

<h3>Export Symbols</h3>

<p>There is one last important step you need to do : you must configure the linker to indicate that two symbols, &ldquo;MyTestedPluginFactory&rdquo; and &ldquo;MyTestedPluginEntry&rdquo; , are available for use in your component.</p>

<p>Create a file MyTestedPluginEntry.exp that contains :</p>

<pre><code>_MyTestedPluginFactory
_MyTestedPluginEntry
</code></pre>

<p>Then go to your project build settings and give the path to this file into the key &ldquo;Exported Symbols File&rdquo;.</p>

<h3>Compile, test and go!</h3>

<p>You should be able to compile you Audio Unit  now, but before we go we have to test using <em>auval </em>:</p>

<ol>
<li><p> First, copy your compiled component into ~/Library/Audio/Plug-Ins/Components</p></li>
<li><p> Secondly, open Terminal and type :</p>

<p>auval -v aufx TEST FRED</p></li>
</ol>


<p>In case you&rsquo;ve made a 64 bits plugin, you should rather type :</p>

<pre><code>auval -64 -v aufx TEST FRED
</code></pre>

<p>Auval is processing a bunch of tests to validate your Audio Unit. Since it currently does nothing, you should get the PASS mention and see it in you favourite sequencer as an audio effect.</p>

<h3>Conclusion</h3>

<p>I agree that this tutorial isn&rsquo;t the funniest you&rsquo;ve ever read, but it was necessary to setup our template to move on more interesting things in our next tutorials. We&rsquo;ll soon see how we can make some fun out of this Xcode template.</p>

<p><a href="https://github.com/Sample-Hold/SimpleEmptyAudioEffect">Click here to download the sources for Xcode 4.2.1</a></p>
]]></content>
    </entry>
    
</feed>